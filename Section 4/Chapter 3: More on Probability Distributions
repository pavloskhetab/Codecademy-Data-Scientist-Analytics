More on Probability Distributions

Introduction to the Poisson Distribution
There are numerous probability distributions used to represent almost any random event. 
In the previous lesson, we learned about the binomial distribution to represent events like any number of coin flips 
as well as the normal distribution to represent events such as the height of a randomly selected woman.

The Poisson distribution is another common distribution, and it is used to describe the number of times a certain event occurs within a fixed time or space interval. 
For example, the Poisson distribution can be used to describe the number of cars that pass through a specific intersection between 4pm and 5pm on a given day. 
It can also be used to describe the number of calls received in an office between 1pm to 3pm on a certain day.

The Poisson distribution is defined by the rate parameter, symbolized by the Greek letter lambda, λ.

Lambda represents the expected value — or the average value — of the distribution. For example, if our expected number of customers between 1pm and 2pm is 7, 
then we would set the parameter for the Poisson distribution to be 7. The PMF for the Poisson(7) distribution is as follows:

This plot shows the PMF of the Poisson(7) distribution. The plot is centered around 7 


What does the PMF of the Poisson distribution look like with different values in the lambda parameter?

The plot shows a Poisson distribution with lambda equal to 3. The height of the bars represents the probability of observing the number along the x-axis.

As the parameter lambda increases, the variance — or spread — of possible values increases as well.



Calculating Probabilities of Exact Values Using the Probability Mass Function
The Poisson distribution is a discrete probability distribution, so it can be described by a probability mass function and cumulative distribution function.

We can use the poisson.pmf() method in the scipy.stats library to evaluate the probability of observing a specific number given the parameter (expected value) of a distribution. 
For example, suppose that we expect it to rain 10 times in the next 30 days. The number of times it rains in the next 30 days is “Poisson distributed” with lambda = 10. 
We can calculate the probability of exactly 6 times of rain as follows:

import scipy.stats as stats
# expected value = 10, probability of observing 6
stats.poisson.pmf(6, 10)

Output:

0.06305545800345125

Like previous probability mass functions of discrete random variables, individual probabilities can be summed together to find the probability of observing a value in a range.

For example, if we expect it to rain 10 times in the next 30 days, the number of times it rains in the next 30 days is “Poisson distributed” with lambda = 10. 
We can calculate the probability of 12-14 times of rain as follows:

import scipy.stats as stats
# expected value = 10, probability of observing 12-14
stats.poisson.pmf(12, 10) + stats.poisson.pmf(13, 10) + stats.poisson.pmf(14, 10)

Output:

0.21976538076223123

Code:
import scipy.stats as stats

## Checkpoint 1
# calculate prob_15
prob_15 = stats.poisson.pmf(15,15)

# print prob_15
print(prob_15)

## Checkpoint 
# calculate prob_7_to_9
prob_7_to_9 = stats.poisson.pmf(7, 15) + stats.poisson.pmf(8, 15) + stats.poisson.pmf(9, 15)

# print prob_7_to_9
print(prob_7_to_9)



Calculating Probabilities of a Range using the Cumulative Density Function
We can use the poisson.cdf() method in the scipy.stats library to evaluate the probability of observing a specific number or less given the expected value of a distribution. 
For example, if we wanted to calculate the probability of observing 6 or fewer rain events in the next 30 days when we expected 10, we could do the following:

import scipy.stats as stats
# expected value = 10, probability of observing 6 or less
stats.poisson.cdf(6, 10)

Output:

0.130141420882483

This means that there is roughly a 13% chance that there will be 6 or fewer rainfalls in the month in question.

We can also use this method to evaluate the probability of observing a specific number or more given the expected value of the distribution. 
For example, if we wanted to calculate the probability of observing 12 or more rain events in the next 30 days when we expected 10, we could do the following:

import scipy.stats as stats
# expected value = 10, probability of observing 12 or more
1 - stats.poisson.cdf(11, 10)

Output:

0.30322385369689386

This means that there is roughly a 30% chance that there will be 12 or more rain events in the month in question.

Note that we used 11 in the statement above even though 12 was the value given in the prompt. 
We wanted to calculate the probability of observing 12 or more rains, which includes 12. stats.poisson.cdf(11, 10) evaluates the probability of observing 11 or fewer rains, 
so 1 - stats.poisson.cdf(11, 10) would equal the probability of observing 12 or more rains.

Summing individual probabilities over a wide range can be cumbersome. 
It is often easier to calculate the probability of a range using the cumulative density function instead of the probability mass function. 
We can do this by taking the difference between the CDF of the larger endpoint and the CDF of one less than the smaller endpoint of the range.

For example, while still expecting 10 rainfalls in the next 30 days, we could use the following code to calculate the probability of observing between 12 and 18 rainfall events:

import scipy.stats as stats
# expected value = 10, probability of observing between 12 and 18
stats.poisson.cdf(18, 10) - stats.poisson.cdf(11, 10)

Output:

0.29603734909303947

Code:
import scipy.stats as stats

## Checkpoint 1
# calculate prob_more_than_20
prob_more_than_20 = 1 - stats.poisson.cdf(20, 15)

# print prob_more_than_20
print(prob_more_than_20)

## Checkpoint 
# calculate prob_17_to_21
prob_17_to_21 = stats.poisson.cdf(21, 15) - stats.poisson.cdf(16, 15)

# print prob_17_to_21
print(prob_17_to_21)



Expectation of the Poisson Distribution
Earlier, we mentioned that the parameter lambda (λ) is the expected value (or average value) of the Poisson distribution. But what does this mean?

Let’s put this into context: let’s say we are salespeople, and after many weeks of work, we calculate our average to be 10 sales per week. If we take this value to be our expected value of a Poisson Distribution, the probability mass function will look as follows:

This is a plot of the probability mass function for the Poisson distribution with the expected value equal to 10. The bar at 10 is colored red, and the rest of the bars are colored blue.

The tallest bar represents the value with the highest probability of occurring. In this case, the tallest bar is at 10. This does not, however, mean that we will make 10 sales. It means that on average, across all weeks, we expect our average to equal about 10 sales per week.

Let’s look at this another way. Let’s take a sample of 1000 random values from the Poisson distribution with the expected value of 10. We can use the poisson.rvs() method in the scipy.stats library to generate random values:

import scipy.stats as stats

# generate random variable
# stats.poisson.rvs(lambda, size = num_values)
rvs = stats.poisson.rvs(10, size = 1000)

The histogram of this sampling looks like the following:

This plot is a histogram of 1000 random samples from the Poisson(10) distribution

We can see observations of as low as 2 but as high as 20. The tallest bars are at 9 and 10. If we took the average of the 1000 random samples, we would get:

print(rvs.mean())

Output:

10.009

This value is very close to 10, confirming that over the 1000 observations, the expected value (or average) is 10.

When we talk about the expected value, we mean the average over many observations. 
This relates to the Law of Large Numbers: 
the more samples we have, the more likely samples will resemble the true population, and the mean of the samples will approach the expected value. 
So even though the salesperson may make 3 sales one week, they may make 16 the next, and 11 the week after. 
In the long run, after many weeks, the expected value (or average) would still be 10.

Code:

import scipy.stats as stats
import codecademylib3

from histogram_function import histogram_function

## Checkpoint 1
# lambda = 15, 1000 random draws 
rand_vars = stats.poisson.rvs(15, size = 1000)

## Checkpoint 2
# print the mean of rand_vars
print(rand_vars.mean())

## Checkpoint 3
histogram_function(rand_vars)



Spread of the Poisson Distribution
Probability distributions also have calculable variances. Variances are a way of measuring the spread or dispersion of values and probabilities in the distribution. 
For the Poisson distribution, the variance is simply the value of lambda (λ), meaning that the expected value and variance are equivalent in Poisson distributions.

We know that the Poisson distribution has a discrete random variable and must be greater than 0 (think, a salesperson cannot have less than 0 sales, a shop cannot have fewer than 0 customers), 
so as the expected value increases, the number of possible values the distribution can take on would also increase.

The first plot below shows a Poisson distribution with lambda equal to three, and the second plot shows a Poisson distribution with lambda equal to fifteen. 
Notice that in the second plot, the spread of the distribution increases. Also, take note that the height of the bars in the second bar decrease since there are more possible values in the distribution.

This image shows a Poisson distribution with lambda equal to three.

This image shows a Poisson distribution with lambda equal to fifteen.

As we can see, as the parameter lambda increases, the variance — or spread — of possible values increases as well.

We can calculate the variance of a sample using the numpy.var() method:

import scipy.stats as stats
import numpy as np

rand_vars = stats.poisson.rvs(4, size = 1000)
print(np.var(rand_vars))

Output:

3.864559

Because this is calculated from a sample, it is possible that the variance might not equal EXACTLY lambda. 
However, we do expect it to be relatively close when the sample size is large, like in this example.

Another way to view the increase in possible values is to take the range of a sample (the minimum and maximum values in a set). 
The following code will take draw 1000 random variables from the Poisson distribution with lambda = 4 and then print the minimum and maximum values observed using the .min() and .max() Python functions:

import scipy.stats as stats

rand_vars = stats.poisson.rvs(4, size = 1000)

print(min(rand_vars), max(rand_vars))

Output:

0 12

If we increase the value of lambda to 10, let’s see how the minimum and maximum values change:

import scipy.stats as stats

rand_vars = stats.poisson.rvs(10, size = 1000)

print(min(rand_vars), max(rand_vars))

Output:

1 22

These values are spread wider, indicating a larger variance.

Code:
import scipy.stats as stats
import numpy as np

## For checkpoints 1 and 2
# 5000 draws, lambda = 7
rand_vars_7 = stats.poisson.rvs(7, size = 5000)

## Checkpoint 1
# print variance of rand_vars_7
print(np.var(rand_vars_7))

## Checkpoint 2
# print minimum and maximum of rand_vars_7
print(min(rand_vars_7), max(rand_vars_7))

## For checkpoints 3 and 4
# 5000 draws, lambda = 17
rand_vars_17 = stats.poisson.rvs(17, size = 5000)

## Checkpoint 3
# print variance of rand_vars_17
print(np.var(rand_vars_17))

## Checkpoint 4
# print minimum and maximum of rand_vars_17
print(min(rand_vars_17), max(rand_vars_17))



Expected Value of the Binomial Distribution
Other types of distributions have expected values and variances based on the given parameters, just like the Poisson distribution. 
Recall that the Binomial distribution has parameters n, representing the number of events and p, representing the probability of “success” (or the specific outcome we are looking for occurring).

Consider the following scenario: we flip a fair coin 10 times and count the number of heads we observe. How many heads would you expect to see? 
You might naturally think 5, and you would be right! What we are doing is calculating the expected value without even realizing it. 
We take the 10 coin flips and multiply it by the chance of getting heads, or one-half, getting the answer of 5 heads. And that is exactly the equation for the expected value of the binomial distribution:

Expected(#ofHeads)=E(X)=n×p
Note that if we were counting the number of heads out of 5 fair coin flips, the expected value would be:

5×0.5=2.5
It is ok for the expected value to be a fraction or have decimal values, though it would be impossible to observe 2.5 heads.

Let’s look at a different example. Let’s say we forgot to study, and we are going to guess B on all 20 questions of a multiple-choice quiz. 
If we assume that every letter option (A, B, C, and D) has the same probability of being the right answer for each question, how many questions would we expect to get correct? 
n would equal 20, because there are 20 questions, and p would equal 0.25, because there is a 1 in 4 chance that B will be the right answer. 
Using the equation, we can calculate:

Expected(#rightanswers)=E(X)=20×0.25=5

Code:
## Checkpoint 1
expected_baskets = .85  * 20
print(expected_baskets)

## Checkpoint 2
expected_late = .02 * 180
print(expected_late)



Variance of the Binomial Distribution
The variance of a binomial distribution is how much the expected value of success (from the previous exercise) may vary. 
In other words, it is a measurement of the spread of the probabilities to the mean/expected value.

Variance for the Binomial distribution is similarly calculated to the expected value using the n (# of trials) and p (probability of success) parameters. 
Let’s use the 10 fair coin flips example to try to understand how variance is calculated. Each coin flip has a certain probability of landing as heads or tails: 0.5 and 0.5, respectively.

The variance of a single coin flip will be the probability that the success happens times the probability that it does not happen: p·(1-p), or 0.5 x 0.5. 
Because we have n = 10 number of coin flips, the variance of a single fair coin flip is multiplied by the number of flips. Thus we get the equation:

Variance(#ofHeads)=Var(X)=n×p×(1−p)
Variance(#ofHeads)=10×0.5×(1−0.5)=2.5
​
 
Let’s consider our 20 multiple choice quiz again. The variance around getting an individual question correct would be p·(1-p), or 0.25 x 0.75. 
We then multiply this variance for all 20 questions in the quiz and get:

Variance(#ofCorrectAnswers)&=20×0.25×(1−0.25)=3.75
We would expect to get 5 correct answers, but the overall variance of the probability distribution is 3.75.

Code:
## Checkpoint 1
variance_baskets = 20 * 0.85 * 0.15
print(variance_baskets)

## Checkpoint 2
variance_late = 180 * 0.02 * 0.98
print(variance_late)



Properties of Expectation and Variance
There are several properties of expectation and variance that are consistent through all distributions:

Properties of Expectation
The expected value of two independent random variables is the sum of each expected value separately:

E(X+Y)=E(X)+E(Y)
For example, if we wanted to count the total number of heads between 10 fair quarter flips and 6 fair nickel flips, 
the expected value combined would be 5 heads (from the quarters) and 3 heads (from the nickels) so 8 heads overall.

Multiplying a random variable by a constant a changes the expected value to be a times the expected value of the random variable:

E(aX)=aE(X)
For example, the expected number of heads from 10 fair coin flips is 5. If we wanted to calculate the number of heads from this event run 4 times (40 total coin flips), 
the expected value would now be 4 times the original expected value, or 20.

Adding a constant a to the distribution changes the expected value by the value a:

E(X+a)=E(X)+a
Let’s say that a test was given and graded, and the average grade was 78 out of 100 points. 
If the teacher decided to curve the grade by adding 2 points to everyone’s grade, the average would now be 80 points.

Properties of Variance
Increasing the values in a distribution by a constant a does not change the variance:

Var(X+a)=Var(X)
This is because the variance of a constant is 0 (there is no range for a single number). 
Adding a constant to a random variable does not add any additional variance. Let’s take the previous example with the teacher curving grades: 
though the expected value (or average) of the test changes from 78 to 80, the spread and dispersion (or variance) of the test scores stays the same.

Scaling the values of a random variable by a constant a scales the variance by the constant squared:

Var(aX)=a^2 Var(X)
The variance of the sum of two random variables is the sum of the individual variances:

Var(X+Y)=Var(X)+Var(Y)
This principle ONLY holds if the X and Y are independent random variables. Let’s say that X is the event getting a heads on a single fair coin flip, 
and Y is the event rolling a 2 on a fair six-sided die:

Var(X)=0.5∗(1−0.5)=0.25

Var(Y)=0.167∗(1−0.167)=0.139

Var(X+Y)=Var(X)+Var(Y)=0.25+0.139=0.389

Code:import scipy.stats as stats
import numpy as np

## Checkpoint 1
expected_bonus = 75000 * 0.08 


## Checkpoint 2
num_goals = stats.poisson.rvs(4, size=100)


## Checkpoint 3
print(np.var(num_goals))

## Checkpoint 4
num_goals_2 = num_goals * 2

print(np.var(num_goals_2))



Review
Congrats! We have finished our second lesson on probability distributions! Let’s review some of the things we’ve learned:

The Poisson distribution and its parameter lambda (λ)
How the probability mass function of the Poisson distribution changes with different values of lambda (λ)
Calculating probabilities of specific values and ranges of values from the Poisson distribution
Calculating probabilities of ranges using the cumulative density function of the Poisson distribution
Generating random values from a distribution
Principles of expectation and variance of various distributions
Universal properties of expectation and variance


Instructions
Let’s practice calculating different values from the Poisson distribution. Below are some questions you can try out using script.py. 
If you get stuck, feel free to use solution.py, which contains the answer to each of these questions.

1: You work at ambulance dispatch where the number of calls that come in daily follows the Poisson distribution with lambda equal to 9. 
There’s a rule that a team can go on no more than 12 calls a day. But how often could this happen?

Create a variable calls that is the probability of observing more than 12 calls on a given day. Then print calls.


2: Let’s say that you have to call in a backup team if you have 10 or more calls in a given day. 
But you don’t want to have to call in a backup team unless they really will be needed. But what is the probability that they will be called and not needed?

Create and print a variable false_backup that is the probability of observing a minimum of 10 calls, but no more than 12. Then print false_backup.


3: A certain tennis star has a first-serve rate of 62%. Let’s say they serve 80 times in a given match. 
What is the expected value of the number of serves they make?

Create and print a variable expected_serves that is the number of first-serves they are expected to make.


4: At the same first-serve rate, what is the variance of this player’s first-serves?

Create and print a variable variance_serves that is the variance of the player making their first serve.

Code:
