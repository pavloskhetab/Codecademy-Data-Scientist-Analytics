Exploratory Data Analysis: Data Visualization
Learn to explore a dataset by visualizing the data.

Introduction
Data visualization is an important component of Exploratory Data Analysis (EDA) because it allows a data analyst to “look at” their data and 
get to know the variables and relationships between them. In order to choose and design a data visualization, it is important to consider two things:

The question you want to answer (and how many variables that question involves).
The data that is available. (is it quantitative or categorical?)
In this article, we’ll use data visualization to explore a dataset from StreetEasy, which contains information about housing rentals in New York City. 
The first few rows of the dataset are printed below (note that we have subsetted the original data for the purposes of this article):

rental_id	building_id	rent	bedrooms	bathrooms	size_sqft	min_to_subway	floor	building_age_yrs	has_roofdeck	has_elevator	has_gym	neighborhood	borough
0	1545	44518357	2550	0.0	1	480	9	2.0	17	1	1	0	Upper East Side	Manhattan
1	2472	94441623	11500	2.0	2	2000	4	1.0	96	0	0	0	Greenwich Village	Manhattan
2	10234	87632265	3000	3.0	1	1000	4	1.0	106	0	0	0	Astoria	Queens
3	2919	76909719	4500	1.0	1	916	2	51.0	29	0	1	0	Midtown	Manhattan
4	2790	92953520	4795	1.0	1	975	3	8.0	31	0	0	0	Greenwich Village	Manhattan

Univariate analysis
Univariate analysis focuses on a single variable at a time. Univariate data visualizations can help us answer questions like:

What is the typical price of a rental in New York City?
What proportion of NYC rentals have a gym?
Depending on the type of variable (quantitative or categorical) we want to visualize, we need to use slightly different visualizations.

Quantitative variables
Box plots (or violin plots) and histograms are common choices for visually summarizing a quantitative variable. 
These plots are useful because they simultaneously communicate information about minimum and maximum values, central location, and spread. 
Histograms can additionally illuminate patterns that can impact an analysis (eg., skew or multimodality).

For example, suppose we are interested in learning more about the price of apartments in NYC. A good starting place is to plot a box plot of the rent variable. 
We could plot a boxplot of rent as follows:

# Load libraries
import seaborn as sns
import matplotlib.pyplot as plt 

# Create the plot
sns.boxplot(x='rent', data=rentals)
plt.show()

boxplot of rental prices showing that the middle 50% of prices are between 2500 and 5000 dollars per month, with many large outliers

We can see that most rental prices fall within a range of $2500-$5000; 
however, there are many outliers, particularly on the high end. 
For more detail, we can also plot a histogram of the rent variable.

# Create a histogram of the rent variable
sns.displot(rentals.rent, bins=10, kde=False)
plt.show()

A seaborn histogram of the `rent` variable that shows the distribution spread between ten bins.


The histogram highlights the long right-handed tail for rental prices. 
We can get a more detailed look at this distribution by increasing the number of bins:

# Create a histogram of the rent variable
sns.displot(rentals.rent, bins=50, kde=False)
plt.show()

A seaborn histogram of the `rent` variable that shows the distribution spread between fifty bins.


Categorical variables
For categorical variables, we can use a bar plot (instead of a histogram) to quickly visualize the frequency (or proportion) of values in each category. 
For example, suppose we want to know how many apartments are available in each borough. We can visually represent that information as follows:

# Create a barplot of the counts in the borough variable
# The palette parameter will set the color scheme for the plot
sns.countplot(x='borough', data=rentals, palette='winter')
plt.show()

A bar plot displaying the distribution of the `borough` variable. The Manhattan category contains ~3500, Queens ~ 500, and Brooklyn ~ 1000.

Alternatively, we could use a pie chart to communicate the same information:

# Define the labels in pie chart
borough_labels = ["Manhattan", "Brooklyn", "Queens"]
 
# Generate pie chart of boroughs
plt.pie(rentals.borough.value_counts(), labels = borough_labels)
plt.show() 

A pie chart displaying the `borough` variable's distribution.

In general, many data analysts avoid pie charts because people are better at visually comparing areas of rectangles than wedges of a pie. 
For a variable with a small number of categories (i.e., fewer than three), a pie chart is a reasonable choice; however, 
for more complex data, a bar chart is usually preferable.

Bivariate analysis
In many cases, a data analyst is interested in the relationship between two variables in a dataset. 
For example:

Do apartments in different boroughs tend to cost different amounts?
What is the relationship between the area of an apartment and how much it costs?
Depending on the types of variables we are interested in, we need to rely on different kinds of visualizations.

One quantitative variable and one categorical variable
Two good options for investigating the relationship between a quantitative variable and a categorical variable are side-by-side box plots and overlapping histograms.

For example, suppose we want to understand whether apartments in different boroughs cost different amounts. 
We could address this question by plotting side by side box plots of rent by borough:

# Create a box plot of the borough variable relative to rent
sns.boxplot(x='borough', y='rent', data=rentals, palette='Accent')
plt.show()

A seaborn box plot showing the rent prices for each category in the `borough` variable.

This plot indicates that rental prices in Manhattan tend to be higher and have more variation than rental prices in other boroughs. 
We could also investigate the same question in more detail by looking at overlapping histograms of rental prices by borough:

plt.hist(rentals.rent[rentals.borough=='Manhattan'], label='Manhattan', density=True, alpha=.5)
plt.hist(rentals.rent[rentals.borough=='Queens'], label='Queens', density=True, alpha=.5)
plt.hist(rentals.rent[rentals.borough=='Brooklyn'], label='Brooklyn', density=True, alpha=.5)
plt.legend()
plt.show()

Overlapping histograms showing rental prices for each borough

Using this visualization, we can see the long right-handed tail in rental prices, especially for Manhattan, and comparatively low prices in Queens.

Two quantitative variables
A scatter plot is a great option for investigating the relationship between two quantitative variables. 
For example, if we want to explore the relationship between rent and size_sqft, we could create a scatter plot of these two variables:

# Create a scatterplot of the size_sqft variable relative to rent
sns.scatterplot(rentals.size_sqft, rentals.rent)
plt.show()

A seaborn scatterplot with rent values along the y-axis, and square footage values along the x-axis.


The plot indicates that there is a strong positive linear relationship between the cost to rent a property and its square footage. 
Larger properties tend to cost more money.

Two categorical variables
Side by side (or stacked) bar plots are useful for visualizing the relationship between two categorical variables. 
For example, suppose we want to know whether rentals that have an elevator are more likely to have a gym. 
We could plot a side by side bar plot as follows:

sns.countplot(x='has_elevator', hue='has_gym', data=rentals)
plt.show()

barplot with has_elevator on the x-axis, and the number of apartments on the y-axis. 
For buildings with an without elevators, counts are split and colored by whether or not the building has a gym.

This plot tells us that buildings with elevators are approximately equally likely to have a gym or not have a gym; 
meanwhile, apartments without elevators are very unlikely to have a gym.

Multivariate analysis
Sometimes, a data analyst is interested in simultaneously exploring the relationship between three or more variables in a single visualization. 
Many of the visualization methods presented up to this point can include additional variables by using visual cues such as colors, shapes, and patterns. 
For example, we can investigate the relationship between rental price, square footage, and borough by using color to introduce our third variable:

sns.scatterplot(rentals.size_sqft, rentals.rent, hue = rentals.borough, palette='bright')
plt.show()

scatter plot of rental prices versus square footage, with each point colored to represent what borough the listing is in

This plot shows many things at once: the positive linear relationship between price and area, 
the fact that Manhattan apartments tend to be larger than the other boroughs (because there are more blue points on the right-hand side of the plot compared to the other colors), 
and that Manhattan apartments tend to cost more money (because the blue points are mostly on top of the green and orange points).

Even though it’s possible to add even more information to this plot (for example, we could use triangles and squares to indicate whether or not an apartment has a gym), 
it’s not always a good idea to overload a single visualization.

Another common data visualization for multivariate analysis is a heat map of a correlation matrix for all quantitative variables:

# Define the colormap which maps the data values to the color space defined with the diverging_palette method  
colors = sns.diverging_palette(150, 275, s=80, l=55, n=9, as_cmap=True)

# Create heatmap using the .corr method on df, set colormap to cmap
sns.heatmap(rentals.corr(), center=0, cmap=colors, robust=True)
plt.show()

heatmap showing correlations between each pair of quantitative variables in the dataset (visualized as a grid of squares, with each variable name labeling the x and y axes). 
Dark purple squares indicate strong correlations, whereas dark green colors indicate negative correlations.

This heat map shows is that the rental price, number of bedrooms, number of bathrooms, 
and size of an apartment are all highly positively correlated (higher values of one are associated with higher values of the others). 
Meanwhile, building age is weakly negatively correlated with rent, bathrooms, minutes to the subway, and 
floor (higher values of building age are associated with lower values of these other variables).

Conclusion
In this article, we’ve summarized some of the important considerations 
for choosing a data visualization based on the question a data analyst wants to answer and the type of data that is available. 
When it comes to designing a visualization, there’s no one right way, 
but “looking” at the data is an important component of both choosing a summary statistic and getting to know a dataset.



Visualizing Multivariate Relationships
An introduction to exploring and visualizing multivariate relationships

Introduction
Exploring multivariate relationships is an important skill to have as a data analyst or scientist. 
You might be familiar with univariate (one variable) and bivariate (two variables) analysis. 
However, datasets often contain more than two features, so it’s important to be able to explore and visualize multiple variables at a time.

In this article, you will learn how to visualize multivariate relationships using:

Scatter plots with visual cues
Grouped box plots
Multi-dimensional plots
Let’s get started!

Scatter plots with visual cues
One way to represent multivariate relationships is to use visual cues such as colors, shapes, and sizes in a scatter plot. 
Let’s demonstrate an example using life expectancy data from the World Health Organization.

First, let’s load in the data:

# import libraries
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt 

# load in health data
health_data = pd.read_csv('life_expectancy_data.csv')

Next, let’s create a scatter plot using Python’s seaborn library to visualize the relationship between years of education and life expectancy:

# create scatter plot
sns.scatterplot(x = 'Schooling', y = 'LifeExpectancy', data = health_data)
plt.show()

Scatter plot showing the relationship between years of schooling and life expectancy

It is clear from this chart that there is a positive relationship between years of schooling and life expectancy.

Let’s make this analysis more interesting by adding a third variable to the scatter plot using color as a visual cue. 
We can do this by passing in a hue argument:

# scatter plot with a visual cue
sns.scatterplot(x = 'Schooling', y = 'LifeExpectancy', hue = 'Status', palette = 'bright', data = health_data)
plt.show()

Scatter plot showing the relationship between years of schooling, life expectancy, and status

This multivariate visualization provides much more insight than the bivariate visualization above. For example, we can see that:

Years of education and life expectancy have a positive relationship
Individuals in developed countries have more years of schooling than individuals in developing countries
The life expectancy in developed countries is greater than the life expectancy in developing countries
Even though it’s possible to add more variables using additional visual cues, it’s not always a great idea to do so. 
For example, let’s try adding a fourth variable to this visualization using shapes as a visual cue:

# scatter plot with four variables
sns.scatterplot(x = 'Schooling', y = 'LifeExpectancy', hue = 'Status', style = 'Year', data = health_data)
plt.show()

Scatter plot with four variables: years of schooling, life expectancy, status, and year

This chart is overloaded with information and is difficult to read. You always want to make sure your charts are readable and easy to interpret. 
Generally, anything beyond three variables in a scatter plot is probably too much for the human eye to process.

Grouped box plots
Grouped box plots can be used to visualize two categorical variables and a quantitative variable. Having the box plots side-by-side can help you gain useful insights.

For example, let’s take a look at Stack Overflow’s Developer Survey data to learn more about how salary is related to education level and gender.

First, let’s load in the data:

# load in salary data
salary_data = pd.read_csv('survey_data.csv')

Next, let’s create a box plot to show the relationship between education and compensation:

# box plot showing relationship between education and compenstation
sns.boxplot(x = "Education", y = "CompTotal", palette = "pastel", data = salary_data)
plt.show()

Box plot showing the relationship between education and compensation

This chart gives us the relationship between education and compensation, but let’s take it a step further to see whether men and women are paid equally. 
We can use the argument hue to group by gender:

# side-by-side box plots grouped by gender
sns.boxplot(x = "Education", y = "CompTotal", hue = "Gender", palette = "pastel", data = salary_data)
plt.show()

Grouped box plots showing the relationship between education and compensation for men and women

This grouped box plot allows us to compare salaries for men and women with the same level of education.

We can see that among adults in the Less than bachelor's, Bachelor's Education, and Master's groups, 
men tend to earn a higher median salary than women with the same level of education; 
however, this pattern is reversed for men and women with Professional degrees.

Multi-dimensional plots
Another way to represent multivariate relationships is to use multi-dimensional plots. 
For example, if we want to represent three variables in a dataset we can create a 3D scatter plot.

We will use the Python graphing library Plotly to load in a dataset and create an interactive 3D plot.

Let’s load in the iris dataset and visualize the relationship between sepal_length, sepal_width, and petal_width for three different iris species:

# import library
import plotly.express as px

# load in iris data
df = px.data.iris()

# create 3D scatter plot
fig = px.scatter_3d(df, x='sepal_length', y='sepal_width', z='petal_width', color='species')
fig.show()

This code outputs a 3D scatter plot that looks like this:

3D scatterplot showing the relationship between three quantitative variables

Notice how there are now three axes instead of two, allowing you to see your data in a new dimension.

3D plots allow you to see relationships that might not be visible in 2D, such as clusters. 
Interactive graphing libraries such as Plotly allow you to rotate the plot to see points from different angles and zoom into specific areas of interest.

The downside of 3D plots is that they can be difficult to read in two dimensions. 
That means that if you need to write a paper report, a 3D plot might not be the best idea.

Review
Datasets often contain many features, which we can use in a model to make predictions or run an analysis. 
Therefore, it’s important to be able to understand and visualize multiple relationships at once.

In this article, you learned how to represent multivariate data using:

Scatter plots with visual cues
Grouped box plots
Multi-dimensional plots
You are now better equipped to create more meaningful visualizations and to think beyond just simple univariate and bivariate terms.

At the same time, it’s also important to recognize that adding too much to a single visualization makes it more difficult to understand relationships, 
so there’s a limit to what we can explore all at once.



Visualizing Time Series Data With Python
An introduction to exploring and visualizing time series data with Python.

Introduction
Data represented in a single point in time is known as cross-sectional data. 
As a Data Scientist or Analyst, sometimes you might encounter data that is collected over periods of time, known as time series data.

Time series data shows up in the real world quite often. For example, weather readings, company stock prices, and sales data are all examples of data that can be tracked over time. 
Therefore, it’s important that you are able to explore and visualize data with a time component.

In this article, you will learn how to explore time series data with Python using the following:

Line plots
Box plots
Heatmaps
Lag plots
Autocorrelation plots
Let’s get started!

Line plot
A line plot is commonly used for visualizing time series data.

In a line plot, time is usually on the x-axis and the observation values are on the y-axis. 
Let’s show an example of this plot using a CSV file of sales data for a small business over a five-year period.

First, let’s import several useful Python libraries and load in our data:

# import libraries
import pandas as pd 
import matplotlib.pyplot as plt
import seaborn as sns

# load in data
sales_data = pd.read_csv("sales_data.csv")

# peek at first few rows of data
sales_data.head()

Here are the first few rows of the sales data:

| date | sales
— | — | — 0 | 2016-01-01 | 2000.0 1 | 2016-01-02 | 1700.0 2 | 2016-01-03 | 1800.0 3 | 2016-01-04 | 1400.0 4 | 2016-01-05 | 1500.0


Let’s create a line plot of the data, with date on the x-axis and sales on the y-axis:

# convert string to datetime64
sales_data["date"] = sales_data["date"].apply(pd.to_datetime)
sales_data.set_index("date", inplace=True)

# create line plot of sales data
plt.plot(sales_data["date"], sales_data["sales"])
plt.xlabel("Date")
plt.ylabel("Sales (USD)")
plt.show()

Line plot showing year on the x-axis and sales in USD on the y-axis

Notice how we can see the trend of the data over time. Looking at the chart, it seems that:

Sales are seasonal, peaking at the beginning and end of each year, and slowing down in the middle of each year.
Sales don’t seem to show signs of growth over time. This appears to be a stagnant business.
Box plot
When working with time series data, box plots can be useful to see the distribution of values grouped by time interval.

For example, let’s create a box plot for each year of sales and put them side-to-side for comparison:

# extract year from date column
sales_data["year"] = sales_data["date"].dt.year

# box plot grouped by year
sns.boxplot(data=sales_data, x="year", y="sales")
plt.show()

Side-by-side box plots for each year of sales showing that median sales are flat over time

For each year of the sales data, we can easily see useful information such as median sales, the highest and lowest sales, the interquartile range of our data, and any outliers.

Median sales for each year (represented by the horizontal line in each box) are quite stable, suggesting that sales are not growing over time.

Heatmap
We can also use a heatmap to compare observations between time intervals in time series data.

For example, let’s create a density heatmap with year on the y-axis and month on the x-axis. 
This can be done by invoking the heatmap() function of the sns Seaborn object:

# calculate total sales for each month
sales = sales_data.groupby(["year", "month"]).sum()

# re-format the data for the heat-map
sales_month_year = sales.reset_index().pivot(index="year", columns="month", values="sales")

# create heatmap
sns.heatmap(sales_month_year, cbar_kws={"label": "Total Sales"})
plt.title("Sales Over Time")
plt.xlabel("Month")
plt.ylabel("Year")
plt.show()

heat map of total sales with month on the x-axis and year on the y-axis

Recall that in a heatmap, as the color gets brighter and moves from dark purple to yellow, the total sales in the corresponding cell is higher.

Here, we see once again that the sales are pretty consistent year after year and also exhibit seasonality.

Lag scatter plot
We can use a lag scatter plot to explore the relationship between an observation and a lag of that observation.

In a time series, a lag is a previous observation:

The observation at a previous time step (the smallest time interval for which we have distinct measurements) is called lag 1.
The observation at two times ago is called lag 2, etc.
In the sales dataset, we have a different sales value for each day. Therefore, the lag 1 value for any particular day is equal to the sales on the previous day. 
The lag 2 value is the sales two days ago, etc.

The plotting module of the pandas library has a built-in lag_plot function that plots the observation at time t on the x-axis and the lag 1 observation (t+1) on the y-axis:

# import lag_plot function
from pandas.plotting import lag_plot

# lag scatter plot
lag_plot(sales_data)
plt.show()

Example of a lag scatter plot using sales data

How can we interpret a lag scatter plot?

If the points move from the bottom left to the top right, this indicates a positive correlation between observations and their lag 1 values. 
For example, high sales on one day are associated with high sales on the previous day.
If the points move from the top left to the bottom right, this indicates a negative correlation between observations and their lag 1 values. 
For example, high sales on one day are associated with low sales on the previous day and vice versa.
If there is no identifiable structure in the lag plot, this indicates the data is random, and there is no association between values at consecutive time points. 
For example, sales on one day tell you no information about expected sales on the following day.
Exploring the relationship between an observation and a lag of that observation is useful for helping us determine whether a dataset is random.

Since the points in the sales data move along a diagonal line from the bottom left to the top right, 
this indicates that our data is not random and there is a positive correlation between observations and their lag 1 values.

Autocorrelation plot
An autocorrelation plot is used to show whether the elements of a time series are positively correlated, negatively correlated, or independent of each other.

This can be plotted with the autocorrelation_plot() function of the pandas.plotting module:

# import autocorrelation function
from pandas.plotting import autocorrelation_plot

# autocorrelation plot
autocorrelation_plot(sales_data)
plt.show()

Autocorrelation plot for sales data with lag on the x-axis and the value of the autocorrelation on the y-axis

In the autocorrelation plot above, lag is on the x-axis and the value of the autocorrelation, which ranges from -1 to 1, is on the y-axis. 
A value near 0 indicates a weak correlation while values closer to -1 and 1 indicate a strong correlation.

Notice how the autocorrelation plot for the sales data forms waves, oscillating between strong negative and positive correlation. 
These waves suggest that our dataset exhibits seasonality.

Also, notice how the autocorrelation decreases over time. This indicates that sales tend to be similar on consecutive days, 
but sales from three years ago are less associated with today’s sales than sales from one year ago.

Review
In this article, you got a brief introduction to exploring and visualizing time series data using:

Line plots
Box plots
Heatmaps
Lag plots
Autocorrelation plots
As a Data Scientist or Analyst, you will often work with data that changes over time. Moving forward, you are now better equipped to explore and visualize data with a time component.



Data Visualizations for Messy Data
Learn how to work around problems with visualizing messy and missing data.

Introduction
Data visualization tutorials generally use pre-processed data. But what about datasets in the wild? What do we do about missing data? 
Or outliers that largely skew visualizations? What do we do when there are too many observations to be interpretable in a scatterplot? 
This article will introduce some of the methods we can use to work around these problems.

Let’s say we are new real estate agents who want to use data to better understand the relationship between the price and the number of bedrooms in a home. 
We will be using a dataset we have called housing from Kaggle on USA Housing Listings.

Missing data
Incomplete observations — or missing data — are generally ignored by plotting functions in commonly-used Python libraries, such as matplotlib and seaborn. 
Therefore, we may want to remove those rows or impute the missing values before plotting. We can check for missing data using .info():

<class 'pandas.core.frame.DataFrame'>
RangeIndex: 384977 entries, 0 to 384976
Data columns (total 17 columns):
 #   Column                   Non-Null Count   Dtype  
---  ------                   --------------   -----  
 0   region                   384977 non-null  object 
 1   price                    384977 non-null  int64  
 2   type                     384977 non-null  object 
 3   sqfeet                   384977 non-null  int64  
 4   beds                     384977 non-null  int64  
 5   baths                    384977 non-null  float64
 6   cats_allowed             384977 non-null  int64  
 7   dogs_allowed             384977 non-null  int64  
 8   smoking_allowed          384977 non-null  int64  
 9   wheelchair_access        384977 non-null  int64  
 10  electric_vehicle_charge  384977 non-null  int64  
 11  comes_furnished          384977 non-null  int64  
 12  laundry_options          305951 non-null  object 
 13  parking_options          244290 non-null  object 
 14  lat                      383059 non-null  float64
 15  long                     383059 non-null  float64
 16  state                    384977 non-null  object 
dtypes: float64(3), int64(9), object(5)
memory usage: 49.9+ MB
None

Based on this output, we may be concerned about the columns laundry_options and parking_options because they have more missing values than other columns.

Preliminary view
Let’s take a first look at two variables and see what issues we run into. Here is a plot of price vs. area in square feet:

A scatterplot with very few points spread out far apart from each other

It doesn’t look like there are many points on this plot, even though there should be over 300,000 points. 
The 1e6 and 1e9 on the x- and y- axes, respectively, indicate that the scale and range for both features is incredibly large. 
For example, we have at least one housing listing that costs almost 3,000,000,000 dollars per month. 
Dealing with these outliers is the first thing we will have to do in order to more effectively visualize the data.

Plotting with outliers
We can whittle down each feature in the plot to cut out outliers until we have a better feel for the data. 
It can take some trial and error to find the right values, so let’s start by limiting price to less than $10,000,000 and sqfeet to less than 2,000,000:

housing2 = housing[(housing.price < 10000000) & (housing.price>0)]
housing2 = housing2[(housing2.sqfeet < 2000000) & (housing2.sqfeet>0)]

sns.scatterplot(housing2['sqfeet'], housing2['price'])

A scatterplot with about 20 points, still spread out far apart from each other

This scatterplot is a little bit better. We can see more points showing in the bottom left-hand side of the plot. 
Let’s get closer to that cluster of points: let’s limit both price and sqfeet to values less than 20,000:

housing2 = housing[(housing.price < 20000) & (housing.price>0)]
housing2 = housing2[(housing2.sqfeet < 20000) & (housing2.sqfeet>0)]

sns.scatterplot(housing2['sqfeet'], housing2['price'])

A scatterplot that has about hundreds of visible points, mostly packed in the bottom left-hand side

Now we are starting to see all of the points! There is still a lot of white space on the right-hand side, 
so let’s limit our data one more time, this time limiting both price and sqfeet to values less than 3,000:

## limit price and sqfeet to < 3000
housing2 = housing[(housing.price < 3000) & (housing.price>0)]
housing2 = housing2[(housing2.sqfeet < 3000) & (housing2.sqfeet>0)]

sns.scatterplot(housing2['sqfeet'], housing2['price'])

A scatterplot with thousands of visible points, evenly spread out through the graph and piled on top of each other

Now we can really see the bulk of the points from our dataset. However there are still so many points here that they are all printed on top of one another. 
This means that we cannot visualize the density of the points and therefore the overall relationship between price and area.

Visualizing many data points
When there are too many data points to visualize, one thing we can do is take a random subset of the data. 
This will mean fewer dots and because it is a random subset, it should still be approximately generalizable to the full dataset. 
Let’s try using a random 5% of the data:

perc = 0.05
housing_sub = housing2.sample(n = int(housing2.shape[0]*perc))

sns.scatterplot(housing_sub['sqfeet'], housing_sub['price'])

A scatterplot of many points, but we’re able to see more of a trend from low to high

There’s still a lot of overlap, but we can actually see the positive linear association between area and price that was difficult to visualize originally.

We can still improve upon this. We can try making each point smaller to better see places of higher concentration of plotted points:

sns.scatterplot(housing_sub['sqfeet'], housing_sub['price'], s = 5)

A scatterplot of many points, but we’re able to see a trend from low to high and a higher concentration of points in the lower section

This plot is better than the previous one because, at a glance, we can see the higher concentration of points in the 500 to 1500 sqfeet range and the 500 to 2000 price range. 
However this still doesn’t give us a great understanding of just how many points are in this middle cluster. Rather than plotting the points smaller, we may want to make them more see-through. 
This way, we can interpret color intensity to understand the overlap:

sns.scatterplot(housing_sub['sqfeet'], housing_sub['price'], alpha = 0.2)

A scatterplot of many points ranging from darker in the center to lighter in the outer ends

We can see that the bottom section of the plot is darker than the top section. 
This is due to many more points overlapping each other at the lower price levels and fewer points overall as price increases.

We also might consider plotting a LOWESS (Locally Weighted Scatterplot Smoothing) smoother over our data points.
This will draw a line through the approximate average price for each value of sqfeet:

sns.lmplot(x='sqfeet', y='price', data = housing_sub, line_kws={'color': 'black'}, lowess=True)

A scatterplot of many points with a black smooth line with an upward trend through the plot

Though the individual points are more difficult to read, the line gives us information about the relationship between these two features.

Visualizing discrete variables
Let’s say we wanted to look at the relationship between beds and baths in our data set. We can easily plot the scatterplot:

sns.scatterplot('beds', 'baths', data = housing_sub)

A scatterplot with single points at each intersection of possible values

While this plot tells us each combination of number of beds and bathrooms in our data set, it doesn’t tell us how many observations there are. 
This is because both features are discrete values, in this case meaning limited to whole numbers for beds and half numbers for bath. 
So every data point that represents 3 beds and 2 bathrooms is plotted at the exact same spot as the others, perfectly overlapping to look like one point.

Adding a jitter adjusts the spread of points along either (or both) axes in order to more easily see some many points there are in each group:

sns.lmplot('beds', 'baths', data = housing_sub, x_jitter = .15, y_jitter = .15, fit_reg = False)

A scatterplot with squares of points at each intersection of possible values

We can look at this plot and learn a lot more than the previous one. For example, we know that there are fewer points at every bath level when beds is equal to 6 compared to 5.

Log transformation
Sometimes when data are on a log scale, it can be hard to visualize the distribution of the values. 
Features with positive values that are highly right-skewed are prime candidates for log transformation. 
Let’s look at the distribution of price from our dataset:

sns.displot(housing.price)

A distribution plot with what looks like one large peak near 0 and a long right-tail

Here we can see one tall peak on the left-hand side, and a very long right-tail along the x-axis. 
While we could try to trim down the price values like before, it might be beneficial to try plotting the distribution of log price instead:

log_price = housing.price[housing.price>0]
log_price = np.log(log_price)
sns.displot(log_price)
plt.xlabel('log price')

A distribution plot with multiple distinct peaks between 5 and 10

This histogram provides a lot more information than the data in the original form. We can even limit the plot to just be between 5 and 10 to see the distribution more clearly:

sns.displot(log_price)
plt.xlabel('log price')
plt.xlim(5,10)

An up-close distribution plot that generally follows a bell-curve

This plot indicates that log price is unimodal and approximately normally distributed. This is helpful knowledge if we want to build a model to predict prices in the future.

Conclusion
Making interpretable data visualizations is not always as easy as just plotting all of the data. 
Oftentimes, visualizations require some additional steps, such as jittering, making points smaller or more opaque, or transforming the data. 
Following these steps will help you to make more dynamic and interpretable visualizations in the future.



